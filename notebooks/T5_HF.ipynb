{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook adapted from:  \n",
    "https://medium.com/askdata/train-t5-for-text-summarization-a1926f52d281  \n",
    "https://colab.research.google.com/drive/14_A2kM8sOVpzwHn-0pMbfnD2htzI2Nte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import datasets\n",
    "\n",
    "SEED = 2557\n",
    "EXP_NAME = 'exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false  --no-raise-error\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Weights & Biases for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbryanli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "%env WANDB_LOG_MODEL=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nlpgridio3/data/bryanli/projects/stories/glucose\n"
     ]
    }
   ],
   "source": [
    "%cd ../glucose/\n",
    "\n",
    "GLUCOSE_DIR = os.getcwd()\n",
    "TRAIN_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_training_data.tsv')\n",
    "TEST_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_HEADER = ['input', 'output']\n",
    "df_train_orig = pd.read_csv(TRAIN_PATH, sep='\\t', names=T5_HEADER)\n",
    "df_test_orig = pd.read_csv(TEST_PATH, sep='\\t', names=T5_HEADER)\n",
    "df_train_orig['input'] = '#' + df_train_orig['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_ids(story_col):\n",
    "    stories = story_col.unique()\n",
    "    story2id = {story: i for i, story in enumerate(stories)}\n",
    "    return story_col.map(story2id)\n",
    "\n",
    "def make_df(X_input):\n",
    "    '''\n",
    "    Creates an intermediate df, used for later formatting of input/output. Assigns a unique `story_id` to each story \n",
    "    \n",
    "    Args:\n",
    "        X_input (pd.Series): input field of T5 GLUCOSE dataset\n",
    "    '''\n",
    "    X_split = X_input.str.split(': ', 1, expand=True)\n",
    "    dim, story = X_split[0], X_split[1]\n",
    "    selected_split = story.str.split('*', 2, expand=True)\n",
    "    story_before, target_sentence, story_after = selected_split[0], selected_split[1], selected_split[2]\n",
    "    story = story_before + target_sentence + story_after\n",
    "    story_id = get_story_ids(story)\n",
    "    d = {'dim': dim, 'story_before': story_before, 'target': target_sentence, 'story_after': story_after, 'story': story, 'story_id': story_id}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = make_df(df_train_orig['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into train/val sets. We ensure that stories are not shared between the splits by randomly selecting 10% of `story_id` fields for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_ids = df_train['story_id'].unique()\n",
    "ids_train, ids_val = model_selection.train_test_split(story_ids, test_size=.1, random_state=SEED)\n",
    "df_train1 = df_train[df_train['story_id'].isin(ids_train)]\n",
    "df_val1 = df_train[df_train['story_id'].isin(ids_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Generation\n",
    "Here, we frame the task as a generation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_out_df(df):\n",
    "    # for next sentence task, we exclude cases where there are no sentences before or after\n",
    "    df = df[(df['story_before'] != '') & (df['story_after'] != '')].reset_index()\n",
    "    df['input'] = df['dim'] + ': ' + df['story_before'].str.strip()\n",
    "    df['output'] = df['target']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task set up is  \n",
    "input = #<dim\\>: <story up to the target sentence\\>  \n",
    "output = <next sentence\\> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = get_in_out_df(df_train1)\n",
    "df_val1 = get_in_out_df(df_val1)\n",
    "df_train1 = df_train1.sample(frac=1, random_state=SEED)\n",
    "df_val1 = df_val1.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_NAME = f'glucose_{EXP_NAME}'\n",
    "wandb.init(name=WANDB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "TOK_SAVE_DIR = f\"{GLUCOSE_DIR}/t5_data/tokenized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.Dataset.from_pandas(df_train1)\n",
    "ds_val = datasets.Dataset.from_pandas(df_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_tgt_len(source_text, target_text):\n",
    "    tokenized_source_text = tokenizer(list(source_text), truncation=False, padding=False)\n",
    "    tokenized_target_text = tokenizer(list(target_text), truncation=False, padding=False)\n",
    "\n",
    "    max_source = 0\n",
    "    for item in tokenized_source_text['input_ids']:\n",
    "        if len(item) > max_source:\n",
    "            max_source = len(item)\n",
    "\n",
    "    max_target = 0\n",
    "    for item in tokenized_target_text['input_ids']:\n",
    "        if len(item) > max_target:\n",
    "            max_target = len(item)\n",
    "    return max_source, max_target\n",
    "\n",
    "max_source, max_target = get_src_tgt_len(df_train1['input'], df_train1['output'])\n",
    "print(max_source, max_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "def encode(batch):\n",
    "    inp = tokenizer(batch['input'], padding='max_length', truncation=True, max_length=max_source)\n",
    "    outp = tokenizer(batch['output'], padding='max_length', truncation=True, max_length=max_target)\n",
    "    inp['labels'] = outp['input_ids']\n",
    "    return inp\n",
    "\n",
    "BATCH_SIZE_ENCODE = 512\n",
    "\n",
    "ds_train = ds_train.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "ds_val = ds_val.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "\n",
    "ds_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "ds_val.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ds_train.save_to_disk(f'{TOK_SAVE_DIR}/train')\n",
    "# ds_val.save_to_disk(f'{TOK_SAVE_DIR}/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error \n",
    "ds_train = datasets.load_from_disk(f'{TOK_SAVE_DIR}/train')\n",
    "ds_val = datasets.load_from_disk(f'{TOK_SAVE_DIR}/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FORMAT = ['input_ids', 'labels', 'attention_mask']\n",
    "ds_train.set_format(type='torch', columns=COLS_TO_FORMAT)\n",
    "ds_val.set_format(type='torch', columns=COLS_TO_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'\n",
    "\n",
    "OUTPUT_DIR = f'{GLUCOSE_DIR}/outputs/{EXP_NAME}'\n",
    "MODEL_DIR =  f'{OUTPUT_DIR}/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=24,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    # prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.0001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=1000, # How often to save a checkpoint\n",
    "    save_total_limit=4, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name=EXP_NAME, # Wandb run name\n",
    "    logging_steps=1000, # How often to log loss to wandb\n",
    "    eval_steps=1000, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False, # Best model is the one with the lowest loss, not highest.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "\n",
    ")\n",
    "trainer.args._n_gpu = 3\n",
    "trainer.train()\n",
    "trainer.save_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR =  f'{OUTPUT_DIR}/model_lr1e-4'\n",
    "model_ft = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
    "# model_pre = T5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_eval_batch_size=8,\n",
    "    remove_unused_columns=True,\n",
    "    eval_accumulation_steps=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model_ft, args=pred_args)\n",
    "\n",
    "preds, labels, *_ = trainer.predict(ds_val)\n",
    "preds_tokens = preds.argmax(axis=2)\n",
    "\n",
    "decoded_sources = []\n",
    "for row in val_dataset:\n",
    "    print('hi')\n",
    "    decoded_sources.append(tokenizer.decode(row['input_ids']))\n",
    "\n",
    "decoded_preds = [tokenizer.decode(pred) for pred in preds_tokens]\n",
    "decoded_labels = [tokenizer.decode(label) for label in labels]\n",
    "\n",
    "output = pd.DataFrame({'Source Text': decoded_sources, 'Target Text': decoded_labels, 'Generated Text': decoded_preds})\n",
    "output.to_excel(output_dir + \"/predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tokens = preds[0].argmax(axis=2)\n",
    "\n",
    "\n",
    "decoded_sources = []\n",
    "for row in ds_val:\n",
    "    print('hi')\n",
    "    decoded_sources.append(tokenizer.decode(row['input_ids']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoded_preds = [tokenizer.decode(pred) for pred in preds_tokens]\n",
    "decoded_labels = [tokenizer.decode(label) for label in labels]\n",
    "\n",
    "output = pd.DataFrame({'Source Text': decoded_sources, 'Target Text': decoded_labels, 'Generated Text': decoded_preds})\n",
    "output.to_excel(OUTPUT_DIR + \"/predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
