{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook adapted from:  \n",
    "https://medium.com/askdata/train-t5-for-text-summarization-a1926f52d281  \n",
    "https://colab.research.google.com/drive/14_A2kM8sOVpzwHn-0pMbfnD2htzI2Nte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "\n",
    "SEED = 2557\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false  --no-raise-error\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Weights & Biases for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbryanli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "%env WANDB_LOG_MODEL=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_TRAIN = False\n",
    "DO_EVAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nlpgridio3/data/bryanli/projects/stories/glucose\n"
     ]
    }
   ],
   "source": [
    "%cd ../glucose/\n",
    "\n",
    "GLUCOSE_DIR = os.getcwd()\n",
    "TRAIN_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_training_data.tsv')\n",
    "TEST_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_test_data.txt')\n",
    "\n",
    "from scripts import format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_num = '2a'\n",
    "EXP_NAME = f'exp{exp_num}'\n",
    "OUTPUT_DIR = f'{GLUCOSE_DIR}/outputs/{EXP_NAME}'\n",
    "MODEL_DIR =  f'{OUTPUT_DIR}/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting 1: Generation\n",
    "Here, we frame the task as a generation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and format it for our experiments. The options for `exp_num` are:  \n",
    "'1' : input = dim + precontext, output = target sentence  \n",
    "'2a': input = dim + precontext, output = original output (with generalized and contextualized)  \n",
    "'2b': input = dim + precontext + <mask_sent> + postcontext, output = original output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, ids_val = format_data.format_data(TRAIN_PATH, exp_num, split_val=True, seed=SEED)\n",
    "\n",
    "with open(OUTPUT_DIR + '/ids_val.txt', 'w') as f:\n",
    "    f.writelines([f'{idx}\\n' for idx in ids_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: #7: The family hamster had escaped.\n",
      "output: The family hamster has escaped >Causes> We feel(s) worried ** Something_A has escaped >Causes> Some People_A feel(s) worried\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#7: The family hamster had escaped.</td>\n",
       "      <td>The family hamster has escaped &gt;Causes&gt; We fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#1: Kate threw a frisbee to her dog. The dog c...</td>\n",
       "      <td>Kate's dog caught a frisbee &gt;Causes/Enables&gt; K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#4: Kate threw a frisbee to her dog. The dog c...</td>\n",
       "      <td>Kate possess(es) a frisbee &gt;Enables&gt; Kate thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#6: Kate threw a frisbee to her dog. The dog c...</td>\n",
       "      <td>Kate threw the frisbee again &gt;Causes/Enables&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#7: Kate threw a frisbee to her dog. The dog c...</td>\n",
       "      <td>Kate threw the frisbee again &gt;Causes&gt; Kate fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216779</th>\n",
       "      <td>#4: Simon invited Joey over for a playdate.</td>\n",
       "      <td>simon possess(es) pokemon cards &gt;Enables&gt; joey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216780</th>\n",
       "      <td>#6: Simon invited Joey over for a playdate.</td>\n",
       "      <td>joey thought it would be funny to mess with si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216781</th>\n",
       "      <td>#2: I was watching sports one day.</td>\n",
       "      <td>I want(s) pizza &gt;Motivates&gt; I pick up my phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216782</th>\n",
       "      <td>#4: I was watching sports one day.</td>\n",
       "      <td>He possess(es) a phone &gt;Enables&gt; He picks up h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216783</th>\n",
       "      <td>#6: I was watching sports one day.</td>\n",
       "      <td>I pick up my phone &gt;Causes/Enables&gt; I call to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216784 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "0                     #7: The family hamster had escaped.   \n",
       "1       #1: Kate threw a frisbee to her dog. The dog c...   \n",
       "2       #4: Kate threw a frisbee to her dog. The dog c...   \n",
       "3       #6: Kate threw a frisbee to her dog. The dog c...   \n",
       "4       #7: Kate threw a frisbee to her dog. The dog c...   \n",
       "...                                                   ...   \n",
       "216779        #4: Simon invited Joey over for a playdate.   \n",
       "216780        #6: Simon invited Joey over for a playdate.   \n",
       "216781                 #2: I was watching sports one day.   \n",
       "216782                 #4: I was watching sports one day.   \n",
       "216783                 #6: I was watching sports one day.   \n",
       "\n",
       "                                                   output  \n",
       "0       The family hamster has escaped >Causes> We fee...  \n",
       "1       Kate's dog caught a frisbee >Causes/Enables> K...  \n",
       "2       Kate possess(es) a frisbee >Enables> Kate thre...  \n",
       "3       Kate threw the frisbee again >Causes/Enables> ...  \n",
       "4       Kate threw the frisbee again >Causes> Kate fee...  \n",
       "...                                                   ...  \n",
       "216779  simon possess(es) pokemon cards >Enables> joey...  \n",
       "216780  joey thought it would be funny to mess with si...  \n",
       "216781  I want(s) pizza >Motivates> I pick up my phone...  \n",
       "216782  He possess(es) a phone >Enables> He picks up h...  \n",
       "216783  I pick up my phone >Causes/Enables> I call to ...  \n",
       "\n",
       "[216784 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = df_train.iloc[0]\n",
    "print(f'input: {ex[\"input\"]}')\n",
    "print(f'output: {ex[\"output\"]}')\n",
    "df_train[['input', 'output']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TRAIN:\n",
    "    WANDB_NAME = f'glucose_{EXP_NAME}'\n",
    "    wandb.init(name=WANDB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "if exp_num == '2b':\n",
    "    special_tokens_dict = {'additional_special_tokens': ['<mask_sent>']}\n",
    "    add_toks = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.Dataset.from_pandas(df_train)\n",
    "ds_val = datasets.Dataset.from_pandas(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 161\n"
     ]
    }
   ],
   "source": [
    "def get_src_tgt_len(source_text, target_text):\n",
    "    tokenized_source_text = tokenizer(list(source_text), truncation=False, padding=False)\n",
    "    tokenized_target_text = tokenizer(list(target_text), truncation=False, padding=False)\n",
    "\n",
    "    max_source = 0\n",
    "    for item in tokenized_source_text['input_ids']:\n",
    "        if len(item) > max_source:\n",
    "            max_source = len(item)\n",
    "\n",
    "    max_target = 0\n",
    "    for item in tokenized_target_text['input_ids']:\n",
    "        if len(item) > max_target:\n",
    "            max_target = len(item)\n",
    "    return max_source, max_target\n",
    "\n",
    "max_source, max_target = get_src_tgt_len(df_train['input'], df_train['output'])\n",
    "print(max_source, max_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1815e7a0f24ea8b5b8bb4f34bd6fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/424 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb673086c8b641d5a137f92bbd11768c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode(batch):\n",
    "    inp = tokenizer(batch['input'], padding='max_length', truncation=True, max_length=max_source)\n",
    "    outp = tokenizer(batch['output'], padding='max_length', truncation=True, max_length=max_target)\n",
    "    inp['labels'] = outp['input_ids']\n",
    "    return inp\n",
    "\n",
    "BATCH_SIZE_ENCODE = 512\n",
    "\n",
    "ds_train = ds_train.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "ds_val = ds_val.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "\n",
    "ds_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "ds_val.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FORMAT = ['input_ids', 'labels', 'attention_mask']\n",
    "ds_train.set_format(type='torch', columns=COLS_TO_FORMAT)\n",
    "ds_val.set_format(type='torch', columns=COLS_TO_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: sally was walking to the park. She found a small kitten in the grass. SHe took the kitten to the park with her to play.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "\n",
      "Sally finds a small kitten >Causes/Enables> Sally puts the kitten into her bookbag ** Someone_A finds Something_A >Causes/Enables> Someone_A puts Something_A into Something_B</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# verify proper encoding\n",
    "print(tokenizer.decode(ds_val[0]['input_ids']))\n",
    "print()\n",
    "print(tokenizer.decode(ds_val[0]['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TRAIN:\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base', cache_dir='/nlp/data/bryanli/.cache')\n",
    "    if exp_num == '2b':\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    ds_train_shuffled = ds_train.shuffle(seed=SEED)\n",
    "    ds_val_shuffled = ds_val.shuffle(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DO_TRAIN:\n",
    "    trainer = None\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_train_epochs=4,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "        # prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "        learning_rate=0.0001,\n",
    "        evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "        save_steps=5000, # How often to save a checkpoint\n",
    "        save_total_limit=4, # Number of maximum checkpoints to save\n",
    "        remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "        run_name=EXP_NAME, # Wandb run name\n",
    "        logging_steps=5000, # How often to log loss to wandb\n",
    "        eval_steps=5000, # How often to run evaluation on the val_set\n",
    "        logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "        load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "        metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "        greater_is_better=False, # Best model is the one with the lowest loss, not highest.\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train_shuffled,\n",
    "        eval_dataset=ds_val_shuffled,\n",
    "\n",
    "    )\n",
    "    trainer.args._n_gpu = 3\n",
    "    trainer.train()\n",
    "    trainer.save_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR =  f'{OUTPUT_DIR}/model'\n",
    "# MODEL_DIR = '/mnt/nlpgridio3/data/bryanli/projects/stories/glucose/outputs/exp2b/model'\n",
    "model_ft = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
    "model_ft = model_ft.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val.set_format(type='torch', columns=COLS_TO_FORMAT, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_sentence(model, tokenizer, input):\n",
    "  inputs = tokenizer.encode(input, return_tensors='pt')\n",
    "  output_sequences = model.generate(\n",
    "      inputs.to(model.device),\n",
    "      pad_token_id=tokenizer.eos_token_id,\n",
    "      max_length=256,\n",
    "  )\n",
    "  \n",
    "  return [tokenizer.decode(x, skip_special_tokens=True) for x in output_sequences]\n",
    "\n",
    "def generate_from_dataset(model, dataset, batch_size=128, skip=True):\n",
    "  output_sequences_all = []\n",
    "  for i in tqdm(range(0, len(dataset), batch_size)):\n",
    "    batch = dataset[i:i+batch_size]\n",
    "    output_sequences = model.generate(\n",
    "        batch['input_ids'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_length=256\n",
    "    )\n",
    "    output_sequences_all.extend(output_sequences)\n",
    "  print(len(output_sequences_all))\n",
    "  return output_sequences_all\n",
    "\n",
    "def decode_seqs(seqs, skip):\n",
    "  return [tokenizer.decode(x, skip_special_tokens=skip) for x in seqs]\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I invited my roommate to dinner >Causes/Enables> My roommate said it was the best steak ever ** Someone_A invited Someone_B to Something_A (that is a meal) >Causes/Enables> Someone_B said it was the best steak ever']\n",
      "['My roommate said he would not go to the steak dinner >Causes/Enables> My roommate ate the steak ** Someone_A said they would not go to Somewhere_A (that is a restaurant) >Causes/Enables> Someone_A ate Something_A (that is a meal)']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333ad4fe5ca946ed9f8034ca66e668b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24154\n"
     ]
    }
   ],
   "source": [
    "print(generate_from_sentence(model_ft, tokenizer, \"#1: I went for a steak dinner. I invited my roommate.\"))\n",
    "print(generate_from_sentence(model_ft, tokenizer, \"#6: I went for a steak dinner. I invited my roommate.\"))\n",
    "preds = generate_from_dataset(model_ft, ds_val, batch_size=128)\n",
    "preds_decoded = decode_seqs(preds, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_num == '2b':\n",
    "    sources_decoded = decode_seqs(ds_val['input_ids'], False)\n",
    "    sources_decoded = [x.split('</s>', 1)[0] for x in sources_decoded]\n",
    "else:\n",
    "    sources_decoded = decode_seqs(ds_val['input_ids'], True)\n",
    "labels_decoded = decode_seqs(ds_val['labels'], True)\n",
    "\n",
    "output = pd.DataFrame({'input': sources_decoded, 'output_true': labels_decoded, 'output_pred': preds_decoded, 'target': df_val['target']})\n",
    "output.to_csv(OUTPUT_DIR + \"/predictions_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EX 0\n",
      "INPUT:   #1: sally was walking to the park. She found a small kitten in the grass. SHe took the kitten to the park with her to play. \n",
      "\n",
      "GOLD:    Sally finds a small kitten >Causes/Enables> Sally puts the kitten into her bookbag ** Someone_A finds Something_A >Causes/Enables> Someone_A puts Something_A into Something_B \n",
      "\n",
      "PRED:    The kitten is at the park >Causes/Enables> The kitten is happy ** Something_A (that is an animal) is at Somewhere_A (that is a park) >Causes/Enables> Something_A is happy \n",
      "\n",
      "TARGET:  When is was time to go home,she put the kitten in her bookbag.\n",
      "-------------------------------------------------- \n",
      "\n",
      "EX 100\n",
      "INPUT:   #6: I went to a children's birthday party. First, I had some cake. Next, I played with some of the kids. \n",
      "\n",
      "GOLD:    I give the birthday boy his gift >Causes/Enables> I leave ** Someone_A gives Someone_B Something_A (that is a gift) >Causes/Enables> Someone_A leaves Somewhere_A (that is Someone_B's location) \n",
      "\n",
      "PRED:    I ate a lot of food >Causes/Enables> I was happy ** Someone_A ate a lot of food >Causes/Enables> Someone_A was happy \n",
      "\n",
      "TARGET:  After, I gave the birthday boy his present.\n",
      "-------------------------------------------------- \n",
      "\n",
      "EX 200\n",
      "INPUT:   #7: Yesterday I went to NYC to see the thanksgiving parade. It was very fun. I loved seeing all the floats. \n",
      "\n",
      "GOLD:    My friends and I have a great time >Causes> We feel(s) happy ** Some People_A have a great time >Causes> Some People_A feel(s) happy \n",
      "\n",
      "PRED:    I bought a toy >Causes> I feel(s) happy ** Someone_A bought Something_A (that is a toy ) >Causes> Someone_A feel(s) happy \n",
      "\n",
      "TARGET:  My friends and I had a great time.\n",
      "-------------------------------------------------- \n",
      "\n",
      "EX 300\n",
      "INPUT:   #1: Darlene and her sister Dorothy lived next door to each other. They would often borrow milk or eggs or bread from one another. One day Darlene went over to Dorothy's to ask to borrow an egg. Dorothy decided to tease her sister and threw the egg at her. \n",
      "\n",
      "GOLD:    Dorothy throws an egg to Darlene >Causes/Enables> Darlene catches the egg ** Someone_A throws an egg to Someone_B >Causes/Enables> Someone_B catches the egg \n",
      "\n",
      "PRED:    Dorothy threw the egg at Darlene >Causes/Enables> Darlene was mad at Dorothy ** Someone_A threw Something_A at Someone_B >Causes/Enables> Someone_B was mad at Someone_A \n",
      "\n",
      "TARGET:  To both of their surprise Darlene caught the egg!\n",
      "-------------------------------------------------- \n",
      "\n",
      "EX 400\n",
      "INPUT:   #2: We went to dinner last night. My wife opened the door. The next morning she could not find her keys or open the door. The keys were in the door and we could not get out. \n",
      "\n",
      "GOLD:    Her sister feel(s) friendship >Motivates> Her sister gets us out ** Someone_A feel(s) friendship >Motivates> Someone_A gets Some People_A out \n",
      "\n",
      "PRED:    My wife feel(s) sad >Motivates> My wife yelled at me ** Someone_A feel(s) sad >Motivates> Someone_A yelled at Someone_B \n",
      "\n",
      "TARGET:  Her sister lives in the building and got us out.\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_TO_PRINT = 5\n",
    "for i in range(NUM_TO_PRINT):\n",
    "    ex = output.iloc[i*100]\n",
    "    print(f'EX {i*100}')\n",
    "    print('INPUT:  ', ex['input'], '\\n')\n",
    "    print('GOLD:   ', ex['output_true'], '\\n')\n",
    "    print('PRED:   ', ex['output_pred'], '\\n')\n",
    "    print('TARGET: ', ex['target'])\n",
    "    print('-' * 50, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stories] *",
   "language": "python",
   "name": "conda-env-stories-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
