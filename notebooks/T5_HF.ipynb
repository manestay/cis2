{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook adapted from:  \n",
    "https://medium.com/askdata/train-t5-for-text-summarization-a1926f52d281  \n",
    "https://colab.research.google.com/drive/14_A2kM8sOVpzwHn-0pMbfnD2htzI2Nte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from torch import nn\n",
    "\n",
    "SEED = 2557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false  --no-raise-error\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Weights & Biases for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbryanli\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "%env WANDB_LOG_MODEL=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nlpgridio3/data/bryanli/projects/stories/glucose\n"
     ]
    }
   ],
   "source": [
    "%cd ../glucose/\n",
    "\n",
    "GLUCOSE_DIR = os.getcwd()\n",
    "TRAIN_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_training_data.tsv')\n",
    "TEST_PATH = os.path.join(GLUCOSE_DIR, 't5_data/t5_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T5_HEADER = ['input', 'output']\n",
    "df_train_orig = pd.read_csv(TRAIN_PATH, sep='\\t', names=T5_HEADER)\n",
    "df_test_orig = pd.read_csv(TEST_PATH, sep='\\t', names=T5_HEADER)\n",
    "df_train_orig['input'] = '#' + df_train_orig['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_ids(story_col):\n",
    "    stories = story_col.unique()\n",
    "    story2id = {story: i for i, story in enumerate(stories)}\n",
    "    return story_col.map(story2id)\n",
    "\n",
    "def make_df(X_input):\n",
    "    '''\n",
    "    Creates an intermediate df, used for later formatting of input/output. Assigns a unique `story_id` to each story \n",
    "    \n",
    "    Args:\n",
    "        X_input (pd.Series): input field of T5 GLUCOSE dataset\n",
    "    '''\n",
    "    X_split = X_input.str.split(': ', 1, expand=True)\n",
    "    dim, story = X_split[0], X_split[1]\n",
    "    selected_split = story.str.split('*', 2, expand=True)\n",
    "    story_before, target_sentence, story_after = selected_split[0], selected_split[1], selected_split[2]\n",
    "    story = story_before + target_sentence + story_after\n",
    "    story_id = get_story_ids(story)\n",
    "    d = {'dim': dim, 'story_before': story_before, 'target': target_sentence, 'story_after': story_after, 'story': story, 'story_id': story_id}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = make_df(df_train_orig['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into train/val sets. We ensure that stories are not shared between the splits by randomly selecting 10% of `story_id` fields for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_ids = df_train['story_id'].unique()\n",
    "ids_train, ids_val = model_selection.train_test_split(story_ids, test_size=.1, random_state=SEED)\n",
    "df_train1 = df_train[df_train['story_id'].isin(ids_train)]\n",
    "df_val1 = df_train[df_train['story_id'].isin(ids_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Generation\n",
    "Here, we frame the task as a generation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_out_df(df):\n",
    "    # for next sentence task, we exclude cases where there are no sentences before or after\n",
    "    df = df[(df['story_before'] != '') & (df['story_after'] != '')].reset_index()\n",
    "    df['input'] = df['dim'] + ': ' + df['story_before'].str.strip()\n",
    "    df['output'] = df['target']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task set up is  \n",
    "input = #<dim\\>: <story up to the target sentence\\>  \n",
    "output = <next sentence\\> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = get_in_out_df(df_train1)\n",
    "df_val1 = get_in_out_df(df_val1)\n",
    "df_train1 = df_train1.sample(frac=1, random_state=SEED)\n",
    "df_val1 = df_val1.sample(frac=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dim</th>\n",
       "      <th>story_before</th>\n",
       "      <th>target</th>\n",
       "      <th>story_after</th>\n",
       "      <th>story</th>\n",
       "      <th>story_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53538</th>\n",
       "      <td>96957</td>\n",
       "      <td>#2</td>\n",
       "      <td>Mike wanted to earn a pizza party at school. I...</td>\n",
       "      <td>That month, he worked as hard as he could.</td>\n",
       "      <td>Luckily, he got his grade up high enough and ...</td>\n",
       "      <td>Mike wanted to earn a pizza party at school. I...</td>\n",
       "      <td>3146</td>\n",
       "      <td>#2: Mike wanted to earn a pizza party at schoo...</td>\n",
       "      <td>That month, he worked as hard as he could.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57487</th>\n",
       "      <td>103860</td>\n",
       "      <td>#7</td>\n",
       "      <td>My family recently got locked in an escape roo...</td>\n",
       "      <td>The clues were very tricky.</td>\n",
       "      <td>We missed escaping by thirty seconds!</td>\n",
       "      <td>My family recently got locked in an escape roo...</td>\n",
       "      <td>1643</td>\n",
       "      <td>#7: My family recently got locked in an escape...</td>\n",
       "      <td>The clues were very tricky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16717</th>\n",
       "      <td>30188</td>\n",
       "      <td>#5</td>\n",
       "      <td>Gary went to hang with new friends.</td>\n",
       "      <td>They wanted to test him out.</td>\n",
       "      <td>They asked him to tag a train car. He said he...</td>\n",
       "      <td>Gary went to hang with new friends. They wante...</td>\n",
       "      <td>705</td>\n",
       "      <td>#5: Gary went to hang with new friends.</td>\n",
       "      <td>They wanted to test him out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69568</th>\n",
       "      <td>125205</td>\n",
       "      <td>#1</td>\n",
       "      <td>Lynn gets a new dog. She loves her dog. She is...</td>\n",
       "      <td>Her dog runs off away from her.</td>\n",
       "      <td>She cannot catch him and he runs away.</td>\n",
       "      <td>Lynn gets a new dog. She loves her dog. She is...</td>\n",
       "      <td>3154</td>\n",
       "      <td>#1: Lynn gets a new dog. She loves her dog. Sh...</td>\n",
       "      <td>Her dog runs off away from her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132708</th>\n",
       "      <td>237451</td>\n",
       "      <td>#10</td>\n",
       "      <td>Rebecca had a brand new trampoline! She invite...</td>\n",
       "      <td>They all had a blast jumping on the trampoline.</td>\n",
       "      <td>One of them fell off, hit his head, and died.</td>\n",
       "      <td>Rebecca had a brand new trampoline! She invite...</td>\n",
       "      <td>479</td>\n",
       "      <td>#10: Rebecca had a brand new trampoline! She i...</td>\n",
       "      <td>They all had a blast jumping on the trampoline.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80734</th>\n",
       "      <td>145119</td>\n",
       "      <td>#2</td>\n",
       "      <td>I took my dog to the dog park today.</td>\n",
       "      <td>My dog ran around and played with all the othe...</td>\n",
       "      <td>I was starting to get bored of watching dogs ...</td>\n",
       "      <td>I took my dog to the dog park today. My dog ra...</td>\n",
       "      <td>152</td>\n",
       "      <td>#2: I took my dog to the dog park today.</td>\n",
       "      <td>My dog ran around and played with all the othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90785</th>\n",
       "      <td>162861</td>\n",
       "      <td>#6</td>\n",
       "      <td>I tried serving sweet potato fries to my family.</td>\n",
       "      <td>None of them liked them at all.</td>\n",
       "      <td>They left most of them on their plates. We ta...</td>\n",
       "      <td>I tried serving sweet potato fries to my famil...</td>\n",
       "      <td>2689</td>\n",
       "      <td>#6: I tried serving sweet potato fries to my f...</td>\n",
       "      <td>None of them liked them at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118507</th>\n",
       "      <td>212266</td>\n",
       "      <td>#1</td>\n",
       "      <td>Jane was in the bathroom.</td>\n",
       "      <td>But she dropped her phone in the toilet.</td>\n",
       "      <td>It no longer worked. So she needed a new one....</td>\n",
       "      <td>Jane was in the bathroom. But she dropped her ...</td>\n",
       "      <td>2391</td>\n",
       "      <td>#1: Jane was in the bathroom.</td>\n",
       "      <td>But she dropped her phone in the toilet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88687</th>\n",
       "      <td>159058</td>\n",
       "      <td>#2</td>\n",
       "      <td>Ann left the house, nervous for her first day ...</td>\n",
       "      <td>The teacher smiled and showed Ann where to sit.</td>\n",
       "      <td>The girl in front of Ann turned around and sm...</td>\n",
       "      <td>Ann left the house, nervous for her first day ...</td>\n",
       "      <td>3777</td>\n",
       "      <td>#2: Ann left the house, nervous for her first ...</td>\n",
       "      <td>The teacher smiled and showed Ann where to sit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51945</th>\n",
       "      <td>94194</td>\n",
       "      <td>#3</td>\n",
       "      <td>We went to the Beach last week.</td>\n",
       "      <td>The baby love to play in the sand.</td>\n",
       "      <td>I could not believe it when she started to ea...</td>\n",
       "      <td>We went to the Beach last week. The baby love ...</td>\n",
       "      <td>1802</td>\n",
       "      <td>#3: We went to the Beach last week.</td>\n",
       "      <td>The baby love to play in the sand.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166018 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  dim                                       story_before  \\\n",
       "53538    96957   #2  Mike wanted to earn a pizza party at school. I...   \n",
       "57487   103860   #7  My family recently got locked in an escape roo...   \n",
       "16717    30188   #5               Gary went to hang with new friends.    \n",
       "69568   125205   #1  Lynn gets a new dog. She loves her dog. She is...   \n",
       "132708  237451  #10  Rebecca had a brand new trampoline! She invite...   \n",
       "...        ...  ...                                                ...   \n",
       "80734   145119   #2              I took my dog to the dog park today.    \n",
       "90785   162861   #6  I tried serving sweet potato fries to my family.    \n",
       "118507  212266   #1                         Jane was in the bathroom.    \n",
       "88687   159058   #2  Ann left the house, nervous for her first day ...   \n",
       "51945    94194   #3                   We went to the Beach last week.    \n",
       "\n",
       "                                                   target  \\\n",
       "53538          That month, he worked as hard as he could.   \n",
       "57487                         The clues were very tricky.   \n",
       "16717                        They wanted to test him out.   \n",
       "69568                     Her dog runs off away from her.   \n",
       "132708    They all had a blast jumping on the trampoline.   \n",
       "...                                                   ...   \n",
       "80734   My dog ran around and played with all the othe...   \n",
       "90785                     None of them liked them at all.   \n",
       "118507           But she dropped her phone in the toilet.   \n",
       "88687     The teacher smiled and showed Ann where to sit.   \n",
       "51945                  The baby love to play in the sand.   \n",
       "\n",
       "                                              story_after  \\\n",
       "53538    Luckily, he got his grade up high enough and ...   \n",
       "57487               We missed escaping by thirty seconds!   \n",
       "16717    They asked him to tag a train car. He said he...   \n",
       "69568              She cannot catch him and he runs away.   \n",
       "132708      One of them fell off, hit his head, and died.   \n",
       "...                                                   ...   \n",
       "80734    I was starting to get bored of watching dogs ...   \n",
       "90785    They left most of them on their plates. We ta...   \n",
       "118507   It no longer worked. So she needed a new one....   \n",
       "88687    The girl in front of Ann turned around and sm...   \n",
       "51945    I could not believe it when she started to ea...   \n",
       "\n",
       "                                                    story  story_id  \\\n",
       "53538   Mike wanted to earn a pizza party at school. I...      3146   \n",
       "57487   My family recently got locked in an escape roo...      1643   \n",
       "16717   Gary went to hang with new friends. They wante...       705   \n",
       "69568   Lynn gets a new dog. She loves her dog. She is...      3154   \n",
       "132708  Rebecca had a brand new trampoline! She invite...       479   \n",
       "...                                                   ...       ...   \n",
       "80734   I took my dog to the dog park today. My dog ra...       152   \n",
       "90785   I tried serving sweet potato fries to my famil...      2689   \n",
       "118507  Jane was in the bathroom. But she dropped her ...      2391   \n",
       "88687   Ann left the house, nervous for her first day ...      3777   \n",
       "51945   We went to the Beach last week. The baby love ...      1802   \n",
       "\n",
       "                                                    input  \\\n",
       "53538   #2: Mike wanted to earn a pizza party at schoo...   \n",
       "57487   #7: My family recently got locked in an escape...   \n",
       "16717             #5: Gary went to hang with new friends.   \n",
       "69568   #1: Lynn gets a new dog. She loves her dog. Sh...   \n",
       "132708  #10: Rebecca had a brand new trampoline! She i...   \n",
       "...                                                   ...   \n",
       "80734            #2: I took my dog to the dog park today.   \n",
       "90785   #6: I tried serving sweet potato fries to my f...   \n",
       "118507                      #1: Jane was in the bathroom.   \n",
       "88687   #2: Ann left the house, nervous for her first ...   \n",
       "51945                 #3: We went to the Beach last week.   \n",
       "\n",
       "                                                   output  \n",
       "53538          That month, he worked as hard as he could.  \n",
       "57487                         The clues were very tricky.  \n",
       "16717                        They wanted to test him out.  \n",
       "69568                     Her dog runs off away from her.  \n",
       "132708    They all had a blast jumping on the trampoline.  \n",
       "...                                                   ...  \n",
       "80734   My dog ran around and played with all the othe...  \n",
       "90785                     None of them liked them at all.  \n",
       "118507           But she dropped her phone in the toilet.  \n",
       "88687     The teacher smiled and showed Ann where to sit.  \n",
       "51945                  The baby love to play in the sand.  \n",
       "\n",
       "[166018 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.24<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glucose_exp1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/bryanli/glucose\" target=\"_blank\">https://wandb.ai/bryanli/glucose</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/bryanli/glucose/runs/24dmbtzg\" target=\"_blank\">https://wandb.ai/bryanli/glucose/runs/24dmbtzg</a><br/>\n",
       "                Run data is saved locally in <code>/mnt/nlpgridio3/data/bryanli/projects/stories/glucose/wandb/run-20210331_202913-24dmbtzg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(24dmbtzg)</h1><iframe src=\"https://wandb.ai/bryanli/glucose/runs/24dmbtzg\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd1cd3fb240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_NAME = 'glucose_exp1'\n",
    "wandb.init(name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "TOK_SAVE_DIR = f\"{GLUCOSE_DIR}/t5_data/tokenized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "ds_train = datasets.Dataset.from_pandas(df_train1)\n",
    "ds_val = datasets.Dataset.from_pandas(df_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 31\n"
     ]
    }
   ],
   "source": [
    "def get_src_tgt_len(source_text, target_text):\n",
    "    tokenized_source_text = tokenizer(list(source_text), truncation=False, padding=False)\n",
    "    tokenized_target_text = tokenizer(list(target_text), truncation=False, padding=False)\n",
    "\n",
    "    max_source = 0\n",
    "    for item in tokenized_source_text['input_ids']:\n",
    "        if len(item) > max_source:\n",
    "            max_source = len(item)\n",
    "\n",
    "    max_target = 0\n",
    "    for item in tokenized_target_text['input_ids']:\n",
    "        if len(item) > max_target:\n",
    "            max_target = len(item)\n",
    "    return max_source, max_target\n",
    "\n",
    "max_source, max_target = get_src_tgt_len(df_train1['input'], df_train1['output'])\n",
    "print(max_source, max_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8b7f872e6f4f1d8e9b002d323715da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1c6ff9304f4d05907961ca91112bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "def encode(batch):\n",
    "    inp = tokenizer(batch['input'], padding='max_length', truncation=True, max_length=max_source)\n",
    "    outp = tokenizer(batch['output'], padding='max_length', truncation=True, max_length=max_target)\n",
    "    inp['labels'] = outp['input_ids']\n",
    "    return inp\n",
    "\n",
    "BATCH_SIZE_ENCODE = 512\n",
    "\n",
    "ds_train = ds_train.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "ds_val = ds_val.map(encode, batched=True, batch_size=BATCH_SIZE_ENCODE)\n",
    "\n",
    "ds_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "ds_val.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ds_train.save_to_disk(f'{TOK_SAVE_DIR}/train')\n",
    "# ds_val.save_to_disk(f'{TOK_SAVE_DIR}/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error \n",
    "TOK_SAVE_DIR = f\"{GLUCOSE_DIR}/t5_data/tokenized/\"\n",
    "ds_train = datasets.load_from_disk(f'{TOK_SAVE_DIR}/train')\n",
    "ds_val = datasets.load_from_disk(f'{TOK_SAVE_DIR}/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FORMAT = ['input_ids', 'labels', 'attention_mask']\n",
    "ds_train.set_format(type='torch', columns=COLS_TO_FORMAT)\n",
    "ds_val.set_format(type='torch', columns=COLS_TO_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/b/bryanli/envs/stories/lib64/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='399' max='13836' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  399/13836 03:58 < 2:14:15, 1.67 it/s, Epoch 0.09/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6,7'\n",
    "OUTPUT_DIR = f'{GLUCOSE_DIR}/outputs/exp1'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=24,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    # prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=1000, # How often to save a checkpoint\n",
    "    save_total_limit=1, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name=EXP_NAME, # Wandb run name\n",
    "    logging_steps=1000, # How often to log loss to wandb\n",
    "    eval_steps=1000, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False, # Best model is the one with the lowest loss, not highest.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "\n",
    ")\n",
    "trainer.args._n_gpu = 3\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val[0]['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'attention_mask', 'dim', 'index', 'input', 'input_ids', 'labels', 'output', 'story', 'story_after', 'story_before', 'story_id', 'target'],\n",
       "    num_rows: 18778\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
